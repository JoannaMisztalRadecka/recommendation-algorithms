{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation algorithms in Python\n",
    "\n",
    "In this lab, we will implement different recommendation algorithms and evaluate their performance on a movie rating prediction task.\n",
    "\n",
    "**Task 1:** First, we will build a simple item-based kNN recommendation algorithm with different item feature representations. We will visualize the item vectors on a 2D plot.\n",
    "\n",
    "**Task 2:** Next, we will use the `surprise` Python package with different collaborative filtering recommendation algorithm implementations and compare their performance for different hyperparametes setting on a standard movie ratings dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import seaborn as sns\n",
    "import umap \n",
    "import plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Item-based kNN recommendations with different item representations\n",
    "\n",
    "First, we wil implement an item-based approach to recommendations based on k Nearest Neighbors (kNN) model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "We use a small version of the popular MovieLens movie recommendation dataset from GroupLens https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "urllib.request.urlretrieve(data_url, 'movielens.zip')\n",
    "movies_file = zipfile.ZipFile('movielens.zip')\n",
    "data_filename = 'ml-latest-small'\n",
    "\n",
    "ratings = pd.read_csv(movies_file.open('ml-latest-small/ratings.csv'))\n",
    "movies = pd.read_csv(movies_file.open('ml-latest-small/movies.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis \n",
    "First, we perform an exploratory analysis to learn basic characteristics of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the rating time distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['datetime'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "ratings['datetime'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the rating values distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.rating.hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that each user has rated relatively few movies - the rating matrix is sparse which is a significant problem for the recommendation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.groupby('movieId').count()['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.groupby('userId').count()['rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the density of the ratings matrix\n",
    "  <font color='red'>**ToDo:**</font>\n",
    "Matrix density is the fraction of non-zero elements in the matrix:  \n",
    " \n",
    " **density = nr of ratings / (nr of users * nr of items)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(??) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-based kNN recommendations\n",
    "We will test a simple item-based kNN recommender. We will define the similarity between movies for different movie representations and return most similar movies to selected one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_movies(movie_id: int, similarity_df: pd.DataFrame, n_neighbors:int=5):\n",
    "    similar_ids = similarity_df.loc[movie_id].sort_values(ascending=False)[1:n_neighbors+1].reset_index()\n",
    "    return similar_ids.merge(movies, on='movieId')[['title', 'genres']]\n",
    "\n",
    "\n",
    "def plot_2d_movies(movie_vectors: pd.DataFrame, movie_metadata: pd.DataFrame, samp_size: int=2000) -> None:\n",
    "    features_sample = movie_vectors.sample(samp_size)\n",
    "    features_sample_2d = umap.UMAP().fit(features_sample).transform(features_sample)\n",
    "    df = pd.DataFrame(features_sample_2d, index=features_sample.index, columns=['x', 'y'])\n",
    "    df = df.merge(movie_metadata, left_index=True, right_on='movieId')[['x', 'y', 'title', 'genres']]\n",
    "    fig = px.scatter(df, x='x', y='y', hover_name=\"title\", hover_data=['genres'])\n",
    "    fig.update_traces(textposition='top center')\n",
    "    fig.update_layout(height=800)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select an example of a movie for a qualitative evaluation of different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movie = movies.iloc[0]\n",
    "test_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-Based Recommendations\n",
    "\n",
    "As the first approach, we use the content-based features of movies to calculate their similarity - in this case these are the movie genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='red'>**ToDo:**</font>\n",
    "- Use sklearn `CountVectorizer`  to build the content-based the movies features matrix from their genres https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html.\n",
    "- Split the lists of genres with | separator (use argument `token_pattern='[^|]+'` for `CountVectorizer`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = ??\n",
    "content_features = pd.DataFrame(vectorizer.fit_transform(movies['genres']).toarray(), columns=vectorizer.get_feature_names(), index=movies['movieId'])\n",
    "content_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Plot 2D movie representations\n",
    "\n",
    "We will use UMAP algorithm for transforming the multi-dimensional vectors into 2D space and Plotly for interactive plot of 2D vectors: https://plotly.com/python/plotly-express/.\n",
    "\n",
    "You can read more and experiment with UMAP: https://pair-code.github.io/understanding-umap/\n",
    "\n",
    "<font color='red'>**ToDo:**</font>\n",
    "\n",
    "Plot  `content_features` vectors in 2D using `plot_2d_movies` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_2d_movies(movie_vectors=??, movie_metadata=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the similarity measure, we use pairwise cosine similarity between movie feature vectors. This measure is more robust to sparse vectors than the Euclidean distance. We will calculate the similarity matrix for all movies pairs according to this metric.\n",
    "\n",
    "<font color='red'>**ToDo:**</font>\n",
    " - Build the similarity matrix for movies based on their `content_features`. \n",
    " \n",
    " Hint: use `cosine_similarity` function https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_content_mx = ??\n",
    "movie_similarity_content = pd.DataFrame(cosine_similarity_content_mx,\n",
    "                                        columns=content_features.index, \n",
    "                                        index=content_features.index)\n",
    "movie_similarity_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most similar movies to \"Toy Story\" based on the content features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_movies(test_movie['movieId'], movie_similarity_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content-based approach is simple and quite effective (even in the new item situation) but it does not consider the information about the interaction patterns. To address this problem, we will implement a collaborative-filtering kNN recommendation algorithm which calculates the movies similarity based on the user rating matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a user-movie rating matrix\n",
    "First, we will construct the rating matrix $R$. Note that our rating matrix is sparse (there are many empty values) - we fill them with 0s. In this exercise we use a small dataset but for larger ones it is more efficient to use a sparse matrix instead of the dense one (we use a dense matrix due to better readability).\n",
    "\n",
    "<font color='red'>**ToDo:**</font>\n",
    "- Construct a pivot table with user ids as columns, movie ids as index and user-movie ratings as values. \n",
    "\n",
    "Hint: \n",
    "You may use `df.pivot_table(index=..., columns=..., values=...)` https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_mx = ??\n",
    "rating_mx.fillna(0, inplace=True)\n",
    "rating_mx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot  `rating_mx` vectors in 2D using `plot_2d_movies` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_movies(movie_vectors=??, movie_metadata=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='red'>**ToDo:**</font>\n",
    " - Build the similarity matrix for movies based on their `rating_mx`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_cf_mx = ??\n",
    "movie_similarity_cf = pd.DataFrame(cosine_similarity_cf_mx, columns=rating_mx.index, index=rating_mx.index)\n",
    "movie_similarity_cf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_movies(test_movie['movieId'], movie_similarity_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Comparing the performance of different recommendation algorithms \n",
    "In this task, we will use `surprise` python package to evaluate the performance of different collaborative filtering recommendation algorithms on the movie recommendation task for a larger dataset.\n",
    "\n",
    "We will use the build-in MovieLens 100K dataset.\n",
    "\n",
    "https://surprise.readthedocs.io/en/stable/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import NMF, SVD, KNNBasic, KNNWithMeans, KNNWithZScore, NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "def evaluate_models(models: list, param_grid: dict, test_metrics: list) -> pd.DataFrame:\n",
    "    results = pd.DataFrame()\n",
    "    for model in models:\n",
    "        print('Evaluating model: {}'.format(model.__name__))\n",
    "        search = GridSearchCV(model, param_grid, measures=test_metrics, cv=cv)\n",
    "        search.fit(data)\n",
    "        model_cv_results = pd.DataFrame(search.cv_results)\n",
    "        model_cv_results['model'] = model.__name__\n",
    "        model_cv_results['params'] = model_cv_results['params'].astype(str)\n",
    "        results = results.append(model_cv_results, sort=False)\n",
    "    return results\n",
    "\n",
    "\n",
    "# use the 100K movie recommendation dataset.\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection \n",
    "\n",
    "We will compare several types of models and search for best configurations.\n",
    "\n",
    "For each group of models prepare a list of classes and parameters for the grid search:\n",
    "\n",
    "`some_models = [SomeModel1, SomeModel2]\n",
    " param_grid = {'param1': [1,2,3],\n",
    "               'param2': [True, False]}`\n",
    "               \n",
    "\n",
    "<font color='red'>**ToDo:**</font>\n",
    "Prepare the configuration for three types of models:\n",
    "* Baseline model: use `NormalPredictor` model which predicts a random rating based on the distribution of the training set. This baseline does not require any parameters (grid will be empty).\n",
    "Docs: https://surprise.readthedocs.io/en/stable/basic_algorithms.html#surprise.prediction_algorithms.random_pred.NormalPredictor\n",
    "\n",
    "* KNN models: use  `KNNBasic`,  `KNNWithZScore`.\n",
    "Prepare the hyperparameters grid for the neighborhood-based models - `k` - number of neighbors (20 and 50) and boolean `user_based` (`True` and `False` for using user or item-based similarity).\n",
    "Docs: https://surprise.readthedocs.io/en/stable/knn_inspired.html\n",
    "\n",
    "* Matrix Factorization models: use `SVD`, `NMF`. Prepare the hyperparameters grid for the MF models - `n_factors` - number of latent dimensions (20 and 50). Docs: https://surprise.readthedocs.io/en/stable/matrix_factorization.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_models = [??]\n",
    "param_grid_baseline = {}\n",
    "\n",
    "\n",
    "knn_models = [??]\n",
    "param_grid_neighbors = {??}\n",
    "\n",
    "\n",
    "mf_models = [??]\n",
    "param_grid_mf = {??}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the grid search and save the results for each model. The best models are selected by minimizing the Mean Absolute Error: $$\\text{MAE} = \\frac{1}{|\\hat{R}|} \\sum_{\\hat{r}_{ui} \\in\n",
    "\\hat{R}}|r_{ui} - \\hat{r}_{ui}|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame()\n",
    "test_metrics = ['mae']\n",
    "\n",
    "cv = 5\n",
    "models_config = [ ('baselines', baseline_models, param_grid_baseline),\n",
    "                ('KNN', knn_models, param_grid_neighbors),\n",
    "                ('MF', mf_models, param_grid_mf)]\n",
    "\n",
    "for model_cls, model_list, model_params in models_config:\n",
    "    print('-------------------------------------------------')\n",
    "    print(f'------ Evaluating model class: {model_cls} --------')\n",
    "    cv_results = cv_results.append(evaluate_models(model_list, model_params, test_metrics), sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics = ['mean_test_mae', 'mean_fit_time', 'mean_test_time']\n",
    "\n",
    "for metric in plot_metrics:\n",
    "    display(cv_results.sort_values(metric)[[\"model\", \"params\", metric]])\n",
    "    fig = sns.barplot(data=cv_results, hue='params', y=metric, x='model')\n",
    "    fig.set_title(metric)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    fig.set_xticklabels(fig.get_xticklabels(), rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
